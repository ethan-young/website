---
title: "Restructuring Data for Dyadic Data Analysis"
author: "Ethan Young"
date: "`r format(Sys.Date(),'%B %d, %Y')`"
output:
  html_document:
    highlight: pygments
    code_folding: show
    theme: "default"
    toc: true
    toc_float:
      smooth_scroll: false
      collapsed: false
    toc_depth: 1
    self_contained: true
    df_print: paged
---

<style>

h1 {
  font-size: 24px;
  font-weight: bold;
}

h2 {
  font-size: 20px;
  font-weight: bold;
}

p{
  font-weight: 350;
}

.r{
  font-size: 10px;
}

h1.title{
  font-size: 28px;
  font-weight: normal;
  margin-top: 10px;
}

h4.author, h4.date{
  font-size: 18px;
  font-style: oblique;
  font-weight: 300;
}

div.main-container{
  margin-left: 0;
  margin-right: 0;
  padding-left: 0;
  padding-right: 0;
}

div#TOC{
  height: 100%;
  max-height: 95%;
  margin-top: 10px;
  margin-bottom: 20px;
}

.r{
  font-size: 12px;
}

</style>

# Introduction

This document will explain how to restructure data *without* a Graphical User Interface (GUI) program e.g. [David Kenny's website]( [http://davidakenny.net/DyadR/RDDD.html). Instead, I will show you how to manipulate data both in a general sense and specifically for dyadic data analysis in a more flexible way by writing my own code and sharing it with you. Be forewarned, writing R-scripts can be frustrating but the payoffs are huge. I highly encourage you to move away from GUIs and start writing scripts for many, many reasons that I won't discuss here.

To manipulate and restructure data, I will be using some really useful R-packages that all have the same underlying philosophy (mostly because they were written by the same guy: Hadley Wickham). I would encourage you to reference his new book [R for Data Science](http://r4ds.had.co.nz/index.html), which explains some very useful theory on [tidy data](http://vita.had.co.nz/papers/tidy-data.html), research workflows, and tools that help execute a data analysis project in clean, reproducible way.

## Data Analysis Philosophy

To me, most of what I have learned in my first 3-1/2 years in graduate school all center around one guiding principle: **Think more. Do less.** In data analysis, it is very easy to do a whole lot without doing much of anything. Programming in R is about **thinking** about what you need, exploring **how** to do so, and **saving** your steps along the way. This can be achieved in almost any statistical software program, however, what I love about R is that you can do nearly every data analysis task in one place. Consider the graphic below:

<br>

<div style="text-align: center">
![](../Figures/Workflow.png)
</div>
 <br>
 
This figure highlights the most important tasks that we as researchers must perform, with the exception of study design and data collection that happen before importing data into your statistical software. You must always import data and make sure it is conforms to the right structure (e.g. import and tidy). Then you must iteratively transform it, visualize it, and model your data until you have gained some kind of insight and can draw some kind of conclusion. Finally, you must communicate your results whether in an informal meeting with your advisers or in a manuscript.

These steps are often fragmented and happen in isolation. For example, you may download data from Qualtrics, open it in Excel and delete irrelevant columns, import it into SPSS, create new variables such as scale scores from a set of items, run an analysis, and then copy and paste the results into Microsoft Word. Each of these steps in your workflow are separated from each other, which creates headaches and substantially impedes reproducibility. With R, and more generally "programming", you can integrate these distinct workflow steps into a single R-script. You can even write up your entire research workflow and contain it within a single dynamic document:

<br>

<div style="text-align: center">
![taken from R for Data Science](../Figures/Programming.png)
</div>
 <br>
 

By using R and Rstudio to write code to integrate all steps in the data analysis pipeline, you can make your life easier, you can think more clearly about data, and you can become a highly flexible and more effective researcher.

This manual is here to help you break-in to the R-programming world. Note that this manual deviates from the way R is traditionally taught. Instead of teaching you the inner workings of how the language works, I aim to give you useful tools you can use right now without having to understand too much about the complexities of R as a programming language. I also aim to teach you a philosophy that will hopefully help you become more effective in your research.

# Research is an Ecosystem

## Data and Scripts: An Analysis Ecosystem

It's useful to think of your research project, and the files associated with it, as an ecosystem. Your research project is a living community of files and data that work together to make reserach happen. For example, a research project almost always contains raw data which in turn needs to be cleaned and transformed it and then analyzed further down the line. After data cleaning, new variabels are created and the analyst must produce figures and tables and eventually write a manuscript. In this process, many, many files are created, which may or may not depend on one or more other files.

Each file in this ecosystem can either have a *symbiotic* or indepent relationship with the overall ecosystem. This is where R and Rstudio become highly useful. Rstudio enables you to access your computer files and use them in a systematic, script-based manner, which allows you to spend more time thinking about your analysis and research goals and less time about the products you need to produce and where they should live.

```{r wds,include=F}
library(data.tree)
knitr::opts_knit$set(root.dir = "../")
```

# R-packages

Packages are bundles of data, code, and functions built by other people that fill a statistical gap or perform special tasks. They can be very general or quite specific. There are many, many R-packages available so it can be a bit overwhelming to sort through which ones are good, bad, or in between. In my experience, I started out by loading every possible R-package that sounded useful or interesting each time I analyzed data. Over time, however, I began to realize that there is both utility and peace-of-mind in simplicity; when it comes to R-packages, sometimes less is more. I also found that not all packages are created equal. In this section, I want to give you a few tips regarding r-packages and introduce you to a set of R-packages that I think revolutionize the way r-code is written and used.

## Reproducibly load packages

At the beginning of any analysis, it is a good idea to load the packages that are necessary to do your analysis. Normally, you do this by using the functions `library()` and/or `require()`. However, I like to take a different approach:

```{r packages, warning=F,message=F}
# pacman is an important package for reproducibility
pacman::p_load(tidyverse,  # all packages in the tidyverse
               haven,      # for reading spss, sas, and stata files
               stringr)    # for working with strings
```

First, notice that I am not using `library()` or `require()` to load the packages I want to use. Instead, I use a function from the package called `pacman`- `p_load()`. `pacman` is a great package for loading other R-packages because it automatically searches your package library for the packages listed inside of `p_load()`. If one or more does not exist, `pacman` will install it and load it for you. This is important for reproducibility because if you share a script with another colleague, they may or may not have installed and loaded the same packages as you, causing your script to break and forcing your colleague to spend time debugging the issue. In my code above, so long as you have installed `pacman`, all other packages necessary to run my script will be installed for you and loaded for use later in the script.

I highly recommend you start using this package, especially for reproducibility issues and collaboration. If your colleagues do not have `pacman`, simply add this line of code before you load your the packages you want for your script:

```{r, eval=F}
install.packages("pacman")
pacman::p_load(tidyverse,haven,stringr) 
```

The `install.packages()` call will install `pacman` for your colleagues (if they do not have the package). Note that I wrote `pacman::p_load()` instead of `p_load()`. This is simply because I do not want to load `pacman` since I do not need it for the rest of the script. By inserting the name of a package and a `::` in front of a function, you can tell R to use functions from packages you have installed without explicitly loading them.

## The `tidyverse`

Notice that I am loading a package called [`tidyverse`](http://tidyverse.org/). This package will load the most commonly used R-packages for importing, tidying, and transforming data. These are: 

- `ggplot2` for plotting
- `tibble` for working with `data.frames` in a more efficient way
- `tidyr` for "tidying" data (more later)
- `readr` for reading tabular data into R
- `purrr` for performing iteration over data structures
- `dplyr` for manipulating and joining data

For our purposes, we will mostly be using `tidyr`, `dplyr`, and `purrr`. We will also be using a package that comes with the `tidyverse` package but is not loaded explicitly by loading the `tidyverse` package: `haven`, which is very useful for loading SPSS, SAS, and Stata files into R. Note that when you install the `tidyverse` package, you will also install many other very useful packages (see below):

```{r tidyverse,message=F,warning=F}
tidyverse_packages() # list all packages including in the tidyverse
```

## Data import: `readr`, `haven`, `readxl`

## Data Manipulation: `dplyr`

Data manipulation is one of the most common tasks necessary for a data analysis project. When I say "data manipulation", I am referring to selecting the relevant columns (i.e. variables), rename them with more useful labels, filtering the relevant rows (i.e. observations or cases), arranging or sorting the observations in ways that help you inspect your data, and creating new variables based on existing variables (e.g. creating scale scores from a set of items). These operations are likely very familiar to you but, at least in my beginning experiences with R, it was not always clear how they were executed in R. On top of this issue, it wasn't clear to me that this process was or could be systematic. `dplyr` makes these operations more explicit and helps you think about how to do such operations systematically. In fact, the so-called 5 most important verbs of `dplyr`do exactly what they sound like:

```{r dplyr_table,echo=F,message=F,warning=F}
library(pixiedust)
data_frame( `function`  = c("`select()`","`rename()`","`filter()`","`arrange()`","`mutate()`"),
            description = c("Select relevant columns of your data",
                            "Rename the columns of your data",
                            "Filter your data according to logical statements",
                            "Sort your data on a certain column, ascending or descending",
                            "Create new variables and add them to your dataset"),
            arguements  = c("`data`, bare unquoted column names",
                            "`data`, bare unquoted column names",
                            "`data`, bare unquoted column names with logical expression (e.g. age < 50)",
                            "`data`, bare unquoted column names, can use desc(column name) to sort descending",
                            "`data`, name of new column = some expression to compute new variable")) %>% 
  knitr::kable()
```

Note that these are not the only useful functions inside of `dplyr`. There are other functions useful for merging data, finding unique rows in your data, summarizing and grouping variables and much more. Here, I just focusing on data manipulation but there note that there are many more tasks that you will undoubtedly face that you can do with `dplyr`.

## Data transformation & Restructuring: `tidyr`

Data transformation is related to data manipulation but is a little different in that (usually) data manipulation is performed once you are sure the *structure* of your data is correct. However, this may not always be the case. In fact, many raw datasets do not come in the right form and either require some careful inspection and cleaning, complete restructuring, or both, which is usually the case. Although it seems pretty basic, it is important to review the structure of your data and ensure that it is [tidy](http://vita.had.co.nz/papers/tidy-data.html). 

Tidy data is when:

- the columns of your dataset represent *one variable*
- rows reflect a *case* or *observation* (remember this can be an individual but it could also be other units of analysis e.g. dyads, schools, countries, etc.)
- cells represent a *value*. 

This may seem basic but that is why it's so important. Often times we assume that our data is tidy when in fact it is not. Therefore, it is important to look at the columns and rows of your data and ask your self "do my columns represent variables or values?" and "are my observations represented each in their own row?". Note that before you *intentially* restructure your data, for example when you *want* to represent your observations across multiple rows for modeling longitudinal data, your data should be tidy. 

You won't often encounter untidy data in psychology, usually because researchers either collect or enter data into a tidy format at the onset of a project. However, it's important not assume your data is tidy as many real world datasets are not tidy. What's more, once you have a firm grasp on tidy data, you will be able to harness previously unusable data and transform it into tidy data ready for analysis.

Below are the powerhouse functions of `tidyr`. They are used to make untidy data tidy. However, they are also used to restructure data into new formats that suite different analytical techniques. Here is a summary of the functions I think are the most important in the `tidyr` package:

```{r tidyr_table,echo=F,message=F,warning=F}
data_frame( `function`  = c("`gather()`","`spread()`","`unite()`","`separate()`"),
            description = c("Take multiple columns and collapse them into key-value pairs, duplicating all other columns as needed",
                            "Spread a key-value pair across multiple columns",
                            "Paste together multiple columns into one",
                            "Turn a single character column into multiple columns"),
            arguements  = c("`data`, `key` = name of your new 'key' column, `value` = name of your new 'value' column, `...` = columns to gather",
                            "`data`, `key` = name of the column whose values will become column headings, `value` = the name of the column that will populate new column headings",
                            "`data`, `col` = name of new column to add, `...` = columns to unite `sep` = the character string that will be used to separate values",
                            "`data`, `col` = column to split up, `into` = names of the new columns, `sep` = the separator to look for to separate columns")) %>% 
  knitr::kable()
```

## Iteration & Functional Programming: `purrr`

# Readable Code

R has the powerful ability to save "objects" through what's called Object Oriented Programming. In essence, this means that when you write some code and "save" it by using the assignment operator, `<-`, you can use that very same object to do new things later in your script. Objects in R can range from very complex, such as all model statistics and data from a structural equation model, to quite simple, such as the result of `2 + 2` which is simply `4` (obviously). 

It is easy to get a little trigger happy when it comes to creating objects in R. For example if you have a complicated set of operations you want to perform on a `data.frame`, such as creating new columns or sub-setting the rows into many different subsamples, you may feel compelled to save the result of each step. There is nothing inherently wrong with doing this, however, creating all these objects clutters up your workspace, which can get in the way of actual analysis, especially when many of these objects are unimportant in the long run.

In some cases, especially when you are doing more "interactive" data analysis, creating many objects may actually make your analysis script break. This happens when you create an object that is then used later in the script. However, over the course of your analysis you either change the original object or delete it all together (unknowingly) and your analysis that uses that object will not work. Debugging a very long script with many objects is tedious and error prone and as such it is advisable to be thoughtful about the objects you create and to seek a minimalist approach to object creation in order to keep things simple and make sure your analysis works every time you run it.

## The pipe operator

The pipe function `%>%` becomes very useful when it comes to performing a set of multiple operations. The pipe operator `%>%` enables you to chain together functions in a linear fashion without needing to save intermediate steps along the way. To understand how the `%>%` works, consider how "normal" R functions work when performing a set of operations:

1. Create some data
2. Filter this data when `x < 300`'
3. Select the variable called `x`
4. Take the mean of `x`

Below is a process that saves each intermediate step of this process e.g. all 4 steps get saved. It's not important that you understand exactly what the code is doing, just that it is performing a set of functions and operations and saving each step of this process.

```{r}
some.data <- data.frame(x = c(340,153,124,132,325,235,346),
                        y = c(45,64,75,34,45,66,32))

sub.data <- filter(some.data,x<300)

sub.data.x <- select(sub.data,x)

sub.data.x <- unlist(sub.data.x)

mean.x.1 <- mean(sub.data.x)

mean.x.1
```

Notice how, to perform this task, you had to create 5 objects, one to represent the data, one for the subset, one for the variable `x`, one for the `unilst()` (don't worry too much about this step), and finally one for the mean of `x` in the subsetted data. The resulting mean of the subsetted `x` is `r mean.x.1`. But, if you are really just interested in the mean of `x`, you don't really need to save all those objects. One way around this problem is to try nesting your functions inside each other:

```{r}
mean.x.2 <- 
  mean(
    unlist(
      select(
        filter(
          data.frame(x = c(340,153,124,132,325,235,346),y = c(45,64,75,34,45,66,32)),
          x < 300),
      x)
    )
  )

mean.x.2
```

This is a little better; you did not have to save all those intermediate steps and you got the correct result: `mean.x.2` = `r mean.x.2`. However, this is also bad practice because nesting functions inside of functions, although syntactically correct, is very difficult for the human eye to read. 

Notice how you must read this code from the inside out: first you create a `data.frame` with variables `x` and `y`, then you `filter` it based on `x < 300`, then you `select x`, `unlist()` the result, and finally you find the `mean` of the `x`. In this case the last function that is called appears first! 

A better way to perform this task is to use the `%>%` as discussed above. The `%>%` comes from the `magrittr` package which is automatically installed and loaded when loading/installing the `tidyverse` package. The `%>%` does not do anything new. It performs all the same actions as nesting functions or creating intermediate objects. The difference is simply how you write your code: 

```{r}
mean.x.3 <- data.frame(x = c(340,153,124,132,325,235,346),
                       y = c(45,64,75,34,45,66,32)) %>% 
  filter(x<300) %>% 
  select(x) %>% 
  unlist() %>% 
  mean()

mean.x.3
```
Put simply, the `%>%` takes the result of function to the left and puts it as the first argument to the next function that is called. This makes `mean(x)` the same as `x %>% mean()`. This allows you to read the code above in a linear, left-to-right fashion: first make a `data.frame`, then take that `data.frame` and `filter` it to when `x < 300`, then `select x` from this subset, `unlist` it, and finally take the `mean` of this result. Again, we find that our `mean.x.3` is the same as the last two versions of this process: `r mean.x.3`.

Note that the default behavior of the pipe operator `%>%` is to put what is on the left into the first argument on the right e.g. `c(1,2,3,4) %>% cbind(c(5,6,7,8))`. Here the vector of numbers `c(1,2,3,4)` gets column-binded, using `cbind()`, to the vector `c(5,6,7,8)`. See below:

```{r,results='markup'}
c(1,2,3,4) %>% cbind(c(5,6,7,8))
```

However, you are not stuck with this behavior. When you use the `%>%`, you can use a period e.g. `.` to tell R where you want the result of the last function to be placed in the next function in your set of operations. For example:

```{r}
# Notice the '.', I want the vector on the left to be the second column, not the first.
c(1,2,3,4) %>% cbind(c(5,6,7,8), .)
```

Notice how the vector `c(1,2,3,4)` now appears in the *second* column in the result of `cbind()`. By using the `.`, I told R *where* to pipe the result.

Throughout this document, I will make good use of the `%>%`. Where necessary, I will use a `.` to show that I am putting the result of a function in a different place than normal. If I don't use the `.`, it means that the result is being placed in the first argument of the subsequent function call.

In general, try to focus on reading my code left-to-right in a step-by-step fashion. If you are interested in learning more about the pipe operator, I encourage you to read [this chapter](http://r4ds.had.co.nz/pipes.html) on pipes from Hadley's [R for Data Science](http://r4ds.had.co.nz/index.html) book.

# Practice data

To begin our data restructuring walk-through, I first downloaded practice data from David Kenny's [data restructuring link](http://davidakenny.net/DyadR/RDDD.htm). Reading through this webpage, it is clear that there are three different ways you might need to restructure data for dyadic data analysis:

1. Converting individual data to dyadic
2. Converting from individual data to pairwise
3. Converting dyadic data to pairwise data

David Kenny's website provides some input data for his data restructuring GUI programs. This is nice because I can download the input data and the output data and check the "correct" output data file against the one that I will produce later.

First, I downloaded all the data and put them in the same folder where I am conducting my analysis. The starting individual level data file is a SPSS file whereas the pairwise and dyadic data files are comma separated value files (.csv). Below I download the files and get them into R. Note how nice it is to work with many and potentially diverse files in one place.

```{r, message=F,warning=F,echo=T}
# Individual level data:
indv <- read_sav("Data/indiv.sav") %>% # Use read_sav for SPSS files
  rename(dyad_id = dyad)          # rename a variable

# Dyadic level data
dyad <- read_csv("Data/dyad.csv",col_types = "dddddddddd")

# Pairwise level data:
pair <- read_csv("Data/pairwise.csv", col_types = "ddddddddddddd")

# Rename columns
names(indv) <- tolower(names(indv)) # | Here I just want to make all
names(dyad) <- tolower(names(dyad)) # | column names lower case
names(pair) <- tolower(names(pair)) # | 
```

# 1. Individual to Dyadic

Going from individual level data to dyadic level data is probably the most straightforward task of the three outlined above. With individual level data, each row represents a "case" or individual. Importantly, each individual is nested within a dyad, as indicated by the `dyad_id` column below.

```{r,message=F,warning=F,echo=F}
indv %>% 
  arrange(dyad_id) %>% 
  dust() %>% 
  sprinkle(part="head",cols=1:ncol(indv),halign="center",pad=5,border="all") %>% 
  sprinkle(part="body",halign="center",border="all") %>% 
  sprinkle(part="body",cols=3:6,bg="lightgray") %>% 
  sprinkle(part="head",cols=3:6,bg="lightgray") %>% 
  sprinkle(rows=indv %>% mutate(row = row_number()) %>% 
             filter(gender==1) %>% 
             select(row) %>% unlist,
           cols=3:6, 
           bg = "darkgray") %>% 
  sprinkle_print_method("html")
```

Note that our task will be to take the cells highlighted in dark gray and make new columns that will become our "partner" data. When we do this, we will be cutting out these rows entirely and our total *N* will be cut in half when we do this. Note that this is possible because our new columns will be named in a way that differentiates partners from actors thus eliminating our need for the `gender` column. Since `dyad_id` is redundant, we only need one row per dyad to distinguish our cases. Thus our resulting data should look like the table below. 

**Note that the dark gray cells are the same rows from the individual level data rows in dark gray above.**

```{r,message=F,warning=F,echo=F}
dyad %>% 
  arrange(dyad_id) %>% 
  dust() %>% 
  sprinkle(part="head",halign="center",pad=5,border="all") %>% 
  sprinkle(part="body",halign="center",border="all") %>% 
  sprinkle(cols=6:9,bg = "darkgray") %>% 
  sprinkle_print_method("html")
```

So let's actually perform this operation using R functions from the `tidyverse` package. Below is the code that I used to convert individual data to dyad level data:

```{r, message=F, warning=F}
indv_dyad <- indv %>%                              # To be explained soon ;)
  arrange(dyad_id) %>%                             # 
  gather(key,value,-dyad_id,-betw,-gender) %>%     #
  mutate(gender = ifelse(gender == 1,"h","w")) %>% #
  unite(new_key,key,gender,sep = "_",remove=T) %>% #
  spread(new_key,value)                            #
```

Let's walk through the code in steps. 

First, I'm taking the starting data `indv` and telling `dplyr` to use the function `arrange()`. I pass the variable `dyad_id` to `arrange()` to tell `dplyr` to sort the columns from the lowest to highest `dyad_id`. This step is unnecessary but I like to arrange data in ways that make sense so I can better reason about the data and the functions I will need to call in order to complete a given data manipulation task.

Next, I use the function `gather()` from the `tidyr` package. This function is powerful; it takes your data set and rearranges it into "key-value pairs". The most basic action `gather()` performs is taking your entire data set and creating two columns: one for the `key` name and the other for the `values`. The first two arguments for `gather()` are `key` and `value`. These are simply arbitrary names that will label the two columns I described above. Next, you can indicate columns that you *don't* want to gather by typing the column name with an `-` in front of it.

For our case, I simply named our `key` and `value` columns "key" and "value" (remember these are arbitrary). Then I told `gather`, don't gather our `dyad_id`, `betw`, and `gender` columns. This simply means that they will be repeated however many times necessary. For our data, we are gathering all the "self" variables (there are 4 * 2 people within each dyad = 8 rows per dyad), thus all of our columns with a `-` sign will be repeated 8 times per dyad.

```{r, message=F, warning=F,eval=F}
indv %>% # <------------ Original data frame
  arrange(dyad_id) %>% # Sort by the dyad_id column
  gather(key,value,    # Gather data into key and value columns
         -dyad_id,# <
         -betw,   # | Do NOT gather these columns,
         -gender) # < repeat them instead
```

```{r,message=F,warning=F,echo=F}
indv %>% 
  arrange(dyad_id) %>% 
  gather(key,value,-dyad_id,-betw,-gender) %>% 
  arrange(dyad_id) %>% 
  select(dyad_id,gender,key,value) %>% 
  dust %>% 
  sprinkle(part="head",halign="center",pad=7,border="all") %>% 
  sprinkle(part="body",halign="center",border="all") %>% 
  sprinkle(part="head",cols=3:4,bg="lightgray") %>% 
  sprinkle(cols=3:4,bg="lightgray") %>% 
  sprinkle_print_method("html")
```

The next step is to make our `key` column more specific. That is, as it currently stands, the rows of the the `key` column only differentiate between each self variable (e.g. self1, self2, etc.). We need this column to differentiate between which self question AND which partner answered the that particular self question. Luckily, we have that information in our `gender` variable. Our next task is to add gender information to our key column. Note that for some reason Dr. Kenny uses the suffixes "_h" and "_w" to differentiate actor and partner self scores so we'll stick with that.

On the line after our call to `gather()`, I use a function called `mutate()`, which creates a new column (i.e. variable) as a function of other columns (variables). Here I just want to match Dr. Kenny's example so I'm going to change `gender` to be coded as `1 = "h"` and `-1 = "w"`. This is achieved by using `mutate()` and using the expression `gender = ifelse(gender==1, "h","w")` inside `mutate`. This tells R to replace `gender` with the result of our `ifelse` call. `ifelse()` is useful because it takes a logical condition as it's first argument, in our case `gender==1`, *for each row* `ifelse()` checks to see if that condition is true. If it is, it replaces the value for that row with the second argument of the `ifelse()`, in our case `"h"`. The third argument of `ifelse()` controls what happens if the condition is not met (i.e. `FALSE`), for example if gender  is not equal to 1. Here we said we want to `ifelse()` to replace `gender` with `"w"` when `gender==1` (i.e. when `gender==-1`).

Now that we have our newly recoded `gender` column, we can `unite()` `gender` with our `key` column. When we call `unite()`, we are asking R to do exactly what it sounds like, "unite" the values of `gender` with `key` into a new column called `new_key`. Note that we can specify and separator string, in our case `"_"` which will separate the values in `key` from `gender`. See below:

Note that the default behavior for `unite()` is to remove the original columns that were used to make the newly united column. This is usually a good idea. Here I've kept them for visualization purposes.

```{r, eval=F}
indv %>% # <------------ Original data frame
  arrange(dyad_id) %>% # Sort by the dyad_id column
  gather(key,value,    # Gather data into key and value columns
         -dyad_id,     # <
         -betw,        # | Do NOT gather these columns, repeat them instead
         -gender) %>%  # <
  unite(new_key,       # <
        key,           # | Create a new variable, "new_key",
        gender,        # | by combining the values of
        sep = "_",     # | "key" and "gender"
        remove=F) # <----- This is normally set to TRUE
```

```{r,message=F,warning=F,echo=F}
indv %>% 
  arrange(dyad_id) %>% 
  gather(key,value,-dyad_id,-betw,-gender) %>% 
  mutate(gender = ifelse(gender == 1,"h","w")) %>% 
  unite(new_key,key,gender,sep = "_",remove=F) %>% 
  arrange(dyad_id) %>% 
  select(dyad_id,key,gender,new_key,value) %>% 
  dust() %>% 
  sprinkle(part="head",halign="center",pad=7,border="all") %>% 
  sprinkle(part="body",halign="center",border="all") %>% 
  sprinkle(part="head",cols=2:3,bg="lightgray") %>% 
  sprinkle(part="head",cols=4,bg="darkgray") %>% 
  sprinkle(part="body",cols=4,bg="darkgray") %>%
  sprinkle(cols=c(2,3),bg="lightgray") %>% 
  sprinkle_print_method("html")
```

The last step in our process is to `spread()` our `new_key` column into new columns and use the `value` column to fill up the cells in these new columns. Remember that our `new_key` column now contains information about actors and partners as well as each of the 4 self variables. Each of these names, for example `self1_h` will become a new column after we use `spread()`. See below:

```{r, eval=F}
indv %>% # <------------ Original data frame
  arrange(dyad_id) %>% # Sort by the dyad_id column
  gather(key,value,    # Gather data into key and value columns
         -dyad_id,     # <
         -betw,        # | Do NOT gather these columns, repeat them instead
         -gender) %>%  # <
  unite(new_key,       # <
        key,           # | Create a new variable, "new_key",
        gender,        # | by combining the values of
        sep = "_",     # | "key" and "gender"
        remove=F) %>%  # <
  spread(new_key,      # Spread the values of "key" into new columns and 
         value)        # fill the cells of these columns with the values of "value"
```

```{r,message=F,warning=F,echo=F}
indv %>% 
  arrange(dyad_id) %>% 
  gather(key,value,-dyad_id,-betw,-gender) %>% 
  arrange(dyad_id) %>% 
  mutate(gender = ifelse(gender == 1,"h","w")) %>% 
  unite(new_key,key,gender,sep = "_",remove = T) %>% 
  spread(new_key,value) %>%
  select(dyad_id,ends_with("_w"),ends_with("_h")) %>% 
  dust() %>% 
  sprinkle(part="head",halign="center",pad=7,border="all") %>% 
  sprinkle(part="body",halign="center",border="all") %>% 
  sprinkle(cols=6:9,bg = "darkgray") %>% 
  sprinkle(part="head",cols=6:9,bg="darkgray") %>% 
  sprinkle_print_method("html")
```

Notice how our newly created data set looks identical to the original `dyad` data downloaded from Dr. Kenny's website. Let's do a formal check. Using the `dplyr` function `setequal()`, we can check to see if there exactly the same number of columns (with the same names) and exactly the same number of rows (with the same exact values):

```{r}
setequal(dyad,indv_dyad) # Match the two data sets, are they equal?
```

They are! YAY!

# 2. Individual to Pairwise

Now that we know how to transform data from the individual level format to a dyadic one, let's go over how to go from an individual level format to a pairwise format. Recall that in individual level data sets, we have one row per individual that is nested within a dyad. In pairwise data structures, we will keep this same general structure. Specifically, our input data file and output data file will have the same number of rows (i.e. the same *N*). The critical difference is that each row will represent BOTH the actor and partner data. That is, each individual's data will be reflected as actor variables for that specific individual's original row but will be reflected as partner data in that specific person's partner row.

To illustrate, let's look at the original individual data set again:

```{r,message=F,warning=F,echo=F}
indv %>% 
  arrange(dyad_id) %>% 
  dust() %>% 
  sprinkle(part="head",cols=1:ncol(indv),halign="center",pad=5,border="all") %>% 
  sprinkle(part="body",halign="center",border="all") %>% 
  sprinkle_print_method("html")
```

Note that we only have one set of "self" variables but each person has unique scores on these variables in their respective rows. What we need to do is add new columns reflecting partner data but *maintain* the same number of rows and inserting data from each dyad member's partner into their row. Here is the output file from Dr. Kenny's website:

```{r,message=F,warning=F,echo=F}
pair %>% 
  arrange(dyad_id) %>% 
  dust() %>% 
  sprinkle(part="head",cols=1:ncol(pair),halign="center",pad=5,border="all") %>% 
  sprinkle(part="body",halign="center",border="all") %>% 
  sprinkle(cols=4:13,bg="lightgray") %>% 
  sprinkle(rows=pair %>% mutate(row = row_number()) %>% 
             filter(gender_a==1) %>% 
             select(row) %>% unlist,
           cols=4:8, 
           bg = "darkgray") %>% 
  sprinkle(rows=pair %>% mutate(row = row_number()) %>% 
             filter(gender_p==1) %>% 
             select(row) %>% unlist,
           cols=9:13, 
           bg = "darkgray") %>% 
  sprinkle_print_method("html")
```

Notice how the data values in rows shaded in either dark gray or light gray are flipped across variables with the suffix "_a" and "_p". This is how the data look when every person's data is reflected as both actor data and partner data. We have the same *N* as before, however, we have 5 new variables that reflect each partner's data.

To see how to do this in R, we need to touch on some of the same concepts as before with Individual to Dyadic transformations. However, because systematically flipping certain pairs of rows and using them to create new columns is a relatively rare thing, I had to write some special code but I think it still fits within our `tidyverse` framework discussed this far.

Below is the code I used to transform the individual data from Dr. Kenny's website to a pairwise format. Let's walk through it:

```{r, message=F, warning=F}
indv_pair <- indv %>% 
  split(.$dyad_id) %>% 
  map_df(function(x){
    
    person1 <- x %>% 
    mutate(act.par = ifelse(gender == 1,"a","p")) %>% 
      gather(key,value,-dyad_id,-betw,-act.par) %>% 
      unite(new_key,key,act.par) %>% 
      spread(new_key,value)
    
    person2 <- x %>% 
      mutate(act.par = ifelse(gender == 1,"p","a")) %>% 
      gather(key,value,-dyad_id,-betw,-act.par) %>% 
      unite(new_key,key,act.par) %>% 
      spread(new_key,value)
    
    bind_rows(person1,person2)
  }) %>% 
  mutate(partnum = ifelse(gender_a == 1,1,2)) %>% 
  select(dyad_id,partnum,betw,ends_with("_a"),ends_with("_p"))
```

First, I want to take the original `indv` data set we worked with in the last walk-through. Here however, I'm going to use a function called `split()`, which will take my data and create mini-data sets based on a grouping variable. Here I want `split` to split my data according to `dyad_id`. Note that, because `split()` is not a `tidyverse` function and because I am using the `pipe` operator i.e `%>%`, I needed to supply `split()` with `.` and the index operator `$` to find the variable `dyad_id` within the `indv` data set. This tells `split()` which variable within `indv` I should split the data by, in this case `dyad_id`. Here is the result:

```{r,eval=F}
indv %>% 
  split(.$dyad_id)
```

```{r,message=F,warning=F,echo=F,results='markup'}
indv %>% 
  arrange(dyad_id) %>% 
  split(.$dyad_id) %>% 
      dust %>% 
      sprinkle(part="head",cols=1:ncol(pair),halign="center",pad=5,border="all") %>% 
      sprinkle(part="body",halign="center",border="all") %>% 
      sprinkle_print_method("html")
```

Next, we will use the `map()` function from the `purrr` package, which is part of the `tidyverse`. `map()` is another very powerful and flexible function that applies a function to each element of a `list` or `data.frame`. Here, `map()` will be applying a function to each of those mini-datasets `split()` created. That is, the result of `split()` is a `list`, which can hold anything inside them, of `data.frames`. Since there is no explicit function for performing pairwise data restructuring, we are going to make our own function. This is where the function `map()` becomes very flexible. It can apply a ready made function to every element of a list or data frame or you can define your own within the call to `map()`, which is what I'm going to do.

Note that I have the suffix `_df` at the end of `map`. This simply means that I want `map()` to make sure that the result is a `data.frame` and nothing else. If my function does not return a `data.frame`, `map()` will throw an error telling me so. Normally, the first argument to `map()` is a `list` or `data.frame` but remember we are piping in the `list` of `data.frame's` that `split()` produced by cutting up `indv` by `dyad_id`. 

Next, we tell `map()` what function to perform to each of our mini-datasets. I use `function(x)` to say that I want to define a new function and it will take the argument `x`. The first thing I want to do is take `x` and do some stuff to it and call it `person1`. Note that `map()` is going to iterate over our `list` of `data.frames` and this means that inside our function `x` represents each individual mini-dataset we created. 

Because we are flipping data around, I'm first going to have `map()` take each mini-dataset and create a new variable using `mutate()` called `act.par`. I'm going to use `ifelse()` to created `act.par` based on `gender`. If `gender==1`, I want `act.par=="a"` and if not I want `act.par=="p"`. I'm using "a" and "p" to refer to actor and partner, respectively. Then I'm going to do some familiar things with `gather()`, `unite()`, and `spread()`. Essentially, I'm gathering up all variables except `dyad_id`, `betw`, and `act.par` (which will get repeated). Then combining `key` and `act.par` and spreading those columns back out. This will result in our mini-dataset having *1* row.

Then I repeat this process for a new object called `person2`. This time, however, `ifelse()` is flipping it's conditions such that if `gender==1` it get's replaced with "p" and "a" if `gender==-1`. For each mini-dataset, I have two objects, `person1` and `person2`. All, I need to do now is put `person1` and `person2` together and I have a pairwise mini-dataset.

Here is what the result would look like for one dyad mini-dataset:

```{r,message=F,warning=F,eval=F}
indv %>% 
  split(.$dyad_id) %>% 
  map_df(function(x){
    
    person1 <- x %>% 
    mutate(act.par = ifelse(gender == 1,"a","p")) %>% 
      gather(key,value,-dyad_id,-betw,-act.par) %>% 
      unite(new_key,key,act.par) %>% 
      spread(new_key,value)
    
    person2 <- x %>% 
      mutate(act.par = ifelse(gender == 1,"p","a")) %>% 
      gather(key,value,-dyad_id,-betw,-act.par) %>% 
      unite(new_key,key,act.par) %>% 
      spread(new_key,value)
    
    bind_rows(person1,person2)
  })
```

Person 1 (gathered)

```{r,message=F,warning=F,echo=F}
indv.gath.1 <- indv %>% 
  filter(dyad_id==3) %>% 
  mutate(act.par = ifelse(gender == 1,"a","p")) %>% 
  gather(key,value,-dyad_id,-betw,-act.par) %>% 
  unite(new_key,key,act.par)

indv.gath.1 %>% 
  dust() %>% 
  sprinkle(part="head",cols=1:ncol(pair),halign="center",pad=5,border="all") %>% 
  sprinkle(part="body",halign="center",border="all") %>% 
  sprinkle(cols=3:4, rows = indv.gath.1 %>% 
             mutate(row = row_number()) %>% 
             filter(str_detect(new_key,"p")) %>% 
             select(row) %>% unlist, bg="lightgray") %>% 
  sprinkle(cols=3:4, rows = indv.gath.1 %>% 
             mutate(row = row_number()) %>% 
             filter(str_detect(new_key,"a")) %>% 
             select(row) %>% unlist, bg="darkgray") %>% 
  sprinkle_print_method("html")
```

Person 1 (spread out)
```{r,message=F,warning=F,echo=F}
indv %>% 
  filter(dyad_id==3) %>% 
  mutate(act.par = ifelse(gender == 1,"a","p")) %>% 
  gather(key,value,-dyad_id,-betw,-act.par) %>% 
  unite(new_key,key,act.par) %>% 
  spread(new_key,value) %>% 
  select(dyad_id,betw,ends_with("_a"),ends_with("_p")) %>% 
  dust() %>% 
  sprinkle(part="head",cols=1:ncol(pair),halign="center",pad=5,border="all") %>% 
  sprinkle(part="body",halign="center",border="all") %>% 
  sprinkle(cols = 3:7,bg="darkgray") %>%
  sprinkle(cols = 8:12,bg="lightgray") %>% 
  sprinkle_print_method("html")
```

Person 2 (gathered)

```{r,message=F,warning=F,echo=F}
indv.gath.2 <- indv %>% 
  filter(dyad_id==3) %>% 
  mutate(act.par = ifelse(gender == 1,"p","a")) %>% 
  gather(key,value,-dyad_id,-betw,-act.par) %>% 
  unite(new_key,key,act.par)

indv.gath.2 %>% 
  dust() %>% 
  sprinkle(part="head",cols=1:ncol(pair),halign="center",pad=5,border="all") %>% 
  sprinkle(part="body",halign="center",border="all") %>% 
  sprinkle(cols=3:4, rows = indv.gath.2 %>% 
             mutate(row = row_number()) %>% 
             filter(str_detect(new_key,"a")) %>% 
             select(row) %>% unlist, bg="lightgray") %>% 
  sprinkle(cols=3:4, rows = indv.gath.2 %>% 
             mutate(row = row_number()) %>% 
             filter(str_detect(new_key,"p")) %>% 
             select(row) %>% unlist, bg="darkgray") %>% 
  sprinkle_print_method("html")
```

Person 2 (spread out)

```{r,message=F,warning=F,echo=F}
indv %>% 
  filter(dyad_id==3) %>% 
  mutate(act.par = ifelse(gender == 1,"p","a")) %>% 
  gather(key,value,-dyad_id,-betw,-act.par) %>% 
  unite(new_key,key,act.par) %>% 
  spread(new_key,value) %>% 
  select(dyad_id,betw,ends_with("_a"),ends_with("_p")) %>% 
  dust() %>% 
  sprinkle(part="head",cols=1:ncol(pair),halign="center",pad=5,border="all") %>% 
  sprinkle(part="body",halign="center",border="all") %>% 
  sprinkle(cols = 3:7,bg="lightgray") %>%
  sprinkle(cols = 8:12,bg="darkgray") %>% 
  sprinkle_print_method("html")
```

Combined mini-dataset

```{r,message=F,warning=F,echo=F}
indv %>% 
  filter(dyad_id==3) %>% 
  split(.$dyad_id) %>% 
  map_df(function(x){
    
    person1 <- x %>% 
      mutate(act.par = ifelse(gender == 1,"a","p")) %>% 
      gather(key,value,-dyad_id,-betw,-act.par) %>% 
      unite(new_key,key,act.par) %>% 
      spread(new_key,value)
    
    person2 <- x %>% 
      mutate(act.par = ifelse(gender == 1,"p","a")) %>% 
      gather(key,value,-dyad_id,-betw,-act.par) %>% 
      unite(new_key,key,act.par) %>% 
      spread(new_key,value)
    
    bind_rows(person1,person2)
  }) %>% 
  select(dyad_id,betw,ends_with("_a"),ends_with("_p")) %>% 
  dust() %>% 
  sprinkle(part="head",cols=1:ncol(pair),halign="center",pad=5,border="all") %>% 
  sprinkle(part="body",halign="center",border="all") %>% 
  sprinkle(rows=1,cols = 3:7,bg="darkgray") %>%
  sprinkle(rows=1,cols = 8:12,bg="lightgray") %>% 
  sprinkle(rows=2,cols = 8:12,bg="darkgray") %>% 
  sprinkle(rows=2,cols = 3:7,bg="lightgray") %>% 
  sprinkle_print_method("html")
```
Recall that a convenient quality of the `purrr` package's `map()` functions is that you can supply a suffix to `map()` such as `map_df()` and that particular `map()` function will be sure to give you a `data.frame` as a result. This means that, although `split()` gave us a `list`, this `list` was comprised of `data.frames` so `map_df()` will automatically combine all of our mini-datasets back into one larger dataset. The result will be our final pairwise-transformed data set. The last two lines just adds a new `partnum` variable to help us remember who is who and then I simply order the variables according the order that Dr. Kenny has them ordered:

```{r,message=F,warning=F,echo=F}
indv %>% 
  split(.$dyad_id) %>% 
  map_df(function(x){
    
    person1 <- x %>% 
      mutate(act.par = ifelse(gender == 1,"a","p")) %>% 
      gather(key,value,-dyad_id,-betw,-act.par) %>% 
      unite(new_key,key,act.par) %>% 
      spread(new_key,value)
    
    person2 <- x %>% 
      mutate(act.par = ifelse(gender == 1,"p","a")) %>% 
      gather(key,value,-dyad_id,-betw,-act.par) %>% 
      unite(new_key,key,act.par) %>% 
      spread(new_key,value)
    
    bind_rows(person1,person2)
  }) %>% 
  mutate(partnum = ifelse(gender_a == 1,1,2)) %>% 
  select(dyad_id,partnum,betw,ends_with("_a"),ends_with("_p")) %>% 
  dust() %>% 
  sprinkle(part="head",cols=1:ncol(pair),halign="center",pad=5,border="all") %>% 
  sprinkle(part="body",halign="center",border="all") %>% 
  sprinkle(cols=4:13,bg="lightgray") %>% 
  sprinkle(rows=pair %>% mutate(row = row_number()) %>% 
             filter(gender_a==1) %>% 
             select(row) %>% unlist,
           cols=4:8, 
           bg = "darkgray") %>% 
  sprinkle(rows=pair %>% mutate(row = row_number()) %>% 
             filter(gender_p==1) %>% 
             select(row) %>% unlist,
           cols=9:13, 
           bg = "darkgray") %>% 
  sprinkle_print_method("html")
```
Is our new pairwise dataset identical to Dr. Kenny's?

```{r}
setequal(pair,indv_pair)
```

It is. It is indeed. ;)

# 3. Dyad to Pairwise

The final case where you might need to restructure your data from a dyadic structure to a pairwise structure. To do this transformation, we will simply do some reverse engineering of the transformations we've already performed. Note that at this point in the tutorial, you've already learned a lot about how to do different transformations using `tidyverse` packages and functions. Now we just need to apply the same skills we've used already to a new situation.

Recall that our dyad data structure has half as many rows as our individual level data. Each row represents a dyad and we have two sets of self ratings - one for the actor and the other for the partner - denoted with a suffix "_a" or "_p". See below:

```{r,message=F,warning=F,echo=F}
dyad %>% 
  arrange(dyad_id) %>% 
  dust() %>% 
  sprinkle(part="head",halign="center",pad=5,border="all") %>% 
  sprinkle(part="body",halign="center",border="all") %>% 
  sprinkle_print_method("html")
```

To move from this dyadic data structure to a pairwise data structure, we need to expand this data again so that we have one row per person (i.e. double the *N*) but we need to keep both sets of "self" variables for actors and partners. Below is the code I use to move from a dyadic data structure to a pairwise structure:

```{r, message=F, warning=F}
dyad_pair <- dyad %>% 
  gather(key,value,-dyad_id,-betw) %>% 
  mutate(gender = ifelse(str_detect(key,"_h"),1,-1),
         key    = str_replace(key,"_w|_h","")) %>%
  spread(key,value) %>% 
  split(.$dyad_id) %>% 
  map_df(function(x){
    
    person1 <- x %>% 
      mutate(act.par = ifelse(gender == 1,"a","p")) %>% 
      gather(key,value,-dyad_id,-betw,-act.par) %>% 
      unite(key,key,act.par) %>% 
      spread(key,value)
    
    person2 <- x %>% 
      mutate(act.par = ifelse(gender == 1,"p","a")) %>% 
      gather(key,value,-dyad_id,-betw,-act.par) %>% 
      unite(key,key,act.par) %>% 
      spread(key,value)
    
    bind_rows(person1,person2)
  }) %>% 
  mutate(partnum = ifelse(gender_a == 1,1,2)) %>% 
  select(dyad_id,partnum,betw,ends_with("_a"),ends_with("_p"))
```

All of this code should look very familiar. In fact, most of it is copied and pasted from our individual to pairwise data restructuring code. This is because the only real difference between dyadic to pairwise and individual to pairwise data transformation is turning dyadic data back into individual level data. After that is complete, we follow the same steps we took when we converted individual to pairwise data transformation.

Note that going from dyadic to individual level data is an easy task because all you need to do perform the reverse actions on the dyadic data that you used to get there in the first place. Note that the functions we have been using from the `tidyr` package (one of the foundational packages in the `tidyverse`) are all reversible. For example, the function `gather()` and `spread()` actually undo each other. The same is true for `unite()` and a function we have not used yet, `separate()`; `unite()` puts the values of two columns together whereas `separate()` breaks them apart, undoing the work of `unite()`. 

To illustrate, let's look at our code from the individual to dyadic data restructuring walk-through. Note steps 1-4:

```{r,eval=F}
indv_dyad <- indv %>%                              # 
  arrange(dyad_id) %>%                             # 
  gather(key,value,-dyad_id,-betw,-gender) %>%     # <- 1) gather
  mutate(gender = ifelse(gender == 1,"h","w")) %>% # <- 2) Recode gender
  unite(new_key,key,gender,sep = "_",remove=T) %>% # <- 3) unite gender and key
  spread(new_key,value) # <---------------------------- 4) spread your colums out
```

And take a look at the code that we will use to go back to individual level data. We will now perform the *reverse* operations (the opposite functions of the above code) in *reverse* order (performing steps 1-4 in reverse order):

```{r,eval=F}
dyad %>%
  gather(key,value,-dyad_id,-betw) %>% # <----------- Undo step 4): use 'gather()' 
  separate(key,c("key","gender"),sep = "_") %>%  # <- Undo step 3): undo 'unite()' 
  mutate(gender = ifelse(gender=="h",1,-1)) %>%  # <- Undo step 2): recode gender  
  spread(key,value) # <------------------------------ Undo step 1): undo gather 
```

1. Here is the result of the first step, undoing `spread()`:

```{r,eval=F}
dyad %>% 
  gather(key,value,-dyad_id,-betw)
```

```{r,message=F,warning=F,echo=F}
dyad %>% 
  arrange(dyad_id) %>% 
  gather(key,value,-dyad_id,-betw) %>% 
  arrange(dyad_id) %>% 
  dust() %>% 
  sprinkle(part="head",halign="center",pad=5,border="all") %>% 
  sprinkle(part="body",halign="center",border="all") %>% 
  sprinkle_print_method("html")
```

2. Now the second step, undoing `unite()`:

```{r,eval=F}
dyad %>% 
  gather(key,value,-dyad_id,-betw) %>% 
  separate(key,c("key","gender"),sep = "_")
```

```{r,message=F,warning=F,echo=F}
dyad %>% 
  arrange(dyad_id) %>% 
  gather(key,value,-dyad_id,-betw) %>% 
  separate(key,c("key","gender"),sep = "_") %>%
  arrange(dyad_id) %>% 
  dust() %>% 
  sprinkle(part="head",halign="center",pad=5,border="all") %>% 
  sprinkle(part="body",halign="center",border="all") %>% 
  sprinkle_print_method("html")
```

3. Next, we recode gender back to -1 and 1:

```{r,eval=F}
dyad %>% 
  gather(key,value,-dyad_id,-betw) %>% 
  separate(key,c("key","gender"),sep = "_") %>% 
  mutate(gender = ifelse(gender=="h",1,-1))
```

```{r,message=F,warning=F,echo=F}
dyad %>% 
  arrange(dyad_id) %>% 
  gather(key,value,-dyad_id,-betw) %>% 
  separate(key,c("key","gender"),sep = "_") %>%
  mutate(gender = ifelse(gender=="h",1,-1)) %>%
  arrange(dyad_id) %>% 
  dust() %>% 
  sprinkle(part="head",halign="center",pad=5,border="all") %>% 
  sprinkle(part="body",halign="center",border="all") %>% 
  sprinkle_print_method("html")
```

4. Finally, we `spread()` the columns back out, undoing `gather()`

```{r,eval=F}
dyad %>% 
  gather(key,value,-dyad_id,-betw) %>% 
  separate(key,c("key","gender"),sep = "_") %>% 
  mutate(gender = ifelse(gender=="h",1,-1)) %>% 
  spread(key,value)
```

```{r,message=F,warning=F,echo=F}
dyad %>% 
  arrange(dyad_id) %>% 
  gather(key,value,-dyad_id,-betw) %>% 
  separate(key,c("key","gender"),sep = "_") %>%
  mutate(gender = ifelse(gender=="h",1,-1)) %>%
  spread(key,value) %>% 
  arrange(dyad_id) %>% 
  dust() %>% 
  sprinkle(part="head",halign="center",pad=5,border="all") %>% 
  sprinkle(part="body",halign="center",border="all") %>% 
  sprinkle_print_method("html")
```

Now our dataset is back to its individual level form. To get to a pairwise data structure, we simply do exactly the same steps we performed in Individual to Pairwise tutorial. Here is the full code again:

```{r, message=F, warning=F,eval=F}
dyad_pair <- dyad %>%                                 # 
  gather(key,value,-dyad_id,-betw) %>%                # 
  mutate(gender = ifelse(str_detect(key,"_h"),1,-1),  # Going back to individual level
         key    = str_replace(key,"_w|_h","")) %>%    # 
  spread(key,value) %>%                               # 
  split(.$dyad_id) %>%                                  #
  map_df(function(x){                                   #
                                                        #
    person1 <- x %>%                                    #
      mutate(act.par = ifelse(gender == 1,"a","p")) %>% #
      gather(key,value,-dyad_id,-betw,-act.par) %>%     # These are the same
      unite(key,key,act.par) %>%                        # steps we took when
      spread(key,value)                                 # we transfomred individual
                                                        # to pairwise data structures
    person2 <- x %>%                                    #
      mutate(act.par = ifelse(gender == 1,"p","a")) %>% #
      gather(key,value,-dyad_id,-betw,-act.par) %>%     #
      unite(key,key,act.par) %>%                        #
      spread(key,value)                                 #
                                                        #
    bind_rows(person1,person2)                          #
  }) %>% 
  mutate(partnum = ifelse(gender_a == 1,1,2)) %>% 
  select(dyad_id,partnum,betw,ends_with("_a"),ends_with("_p"))
```

```{r,message=F,warning=F,echo=F}
dyad %>%                                 # 
  gather(key,value,-dyad_id,-betw) %>%                # 
  mutate(gender = ifelse(str_detect(key,"_h"),1,-1),  # Going back to individual level
         key    = str_replace(key,"_w|_h","")) %>%    # 
  spread(key,value) %>%                               # 
  split(.$dyad_id) %>%                                  #
  map_df(function(x){                                   #
                                                        #
    person1 <- x %>%                                    #
      mutate(act.par = ifelse(gender == 1,"a","p")) %>% #
      gather(key,value,-dyad_id,-betw,-act.par) %>%     # These are the same
      unite(key,key,act.par) %>%                        # steps we took when
      spread(key,value)                                 # we transfomred individual
                                                        # to pairwise data structures
    person2 <- x %>%                                    #
      mutate(act.par = ifelse(gender == 1,"p","a")) %>% #
      gather(key,value,-dyad_id,-betw,-act.par) %>%     #
      unite(key,key,act.par) %>%                        #
      spread(key,value)                                 #
                                                        #
    bind_rows(person1,person2)                          #
  }) %>% 
  mutate(partnum = ifelse(gender_a == 1,1,2)) %>% 
  select(dyad_id,partnum,betw,ends_with("_a"),ends_with("_p")) %>% 
  dust() %>% 
  sprinkle(part="head",cols=1:ncol(pair),halign="center",pad=5,border="all") %>% 
  sprinkle(part="body",halign="center",border="all") %>% 
  sprinkle_print_method("html")
```

Finally, is our `dyad_pair` dataset the same as Dr. Kenny's pairwise dataset?

```{r}
setequal(pair,dyad_pair)
```

Success!!

# Learning More

There is much, much more to learn in R. This includes even more "data" transformation and manipulation techniques but also includes (but is not limited to) plotting, statistics (obviously), reporting, reproducibility, and many other topics. In my opinion, although the statistical packages in R are many and highly useful and effective, the point of learning R should not be to learn/use statistics alone. Instead, you should learn R in order to learn how to *program* and to intimately understand how to work with data. Many professors and professionals alike say that that 80-90% of data analysis is simply preparing the data for analysis (cleaning, transforming, restructuring, exploring etc.). But actually performing your analysis is a matter of a few clicks or running a few lines of code. Programming makes all the steps that come before your analysis much easier and much more systematic. It makes you more flexible, enables you to solve many different problems, and connects your research workflow.

To learn more about how to program in R, I recommend taking a look at the resources below:

**Learn R interactively**

- [Data Camp](www.datacamp.com), I highly recommend creating an account. For students, it costs $9 a month but it's worth it since there are detailed courses that teach you many useful skills.
- [Data Camp Community](www.datacamp.com/community/), these are free courses that you can take.
- [R for Data Science](http://r4ds.had.co.nz/index.html), not interactive but has exercises
- [Advanced R](http://adv-r.had.co.nz/), not interactive but has exercises
- [From Rstudio](https://www.rstudio.com/online-learning/)

**Reproducible Dynamic Documents**

- [Rmarkdown](http://rmarkdown.rstudio.com/), very useful website, highly recommend
- [Knitr](https://yihui.name/knitr/)
- [Bookdown](https://bookdown.org/)

**Statistics**

- [`lavaan`](http://lavaan.ugent.be/), structural equation modeling
- [`psych` package](http://personality-project.org/), SEM, factor analysis, and reliability
- [`lme4`](https://www.rdocumentation.org/packages/lme4/versions/1.1-12/topics/lme4-package?), linear and nonlinear mixed models
- [`nlme`](https://www.rdocumentation.org/packages/nlme/versions/3.1-68.1/topics/nlme?), nonlinear mixed-effects models
- Moderation and simple slopes: [here](https://www.rdocumentation.org/packages/rockchalk/versions/1.8.101) and [here](https://www.rdocumentation.org/packages/pequod/versions/0.0-5)
- Mediation: [here](http://lavaan.ugent.be/tutorial/mediation.html) and [here](https://www.rdocumentation.org/packages/mediation/versions/4.4.5)

**`Tidyverse`**

- [tidy data](http://vita.had.co.nz/papers/tidy-data.html)
- [`tidyverse`](http://tidyverse.org/)
- [`tidyr`](https://github.com/tidyverse/tidyr)
- [`dplyr`](https://github.com/hadley/dplyr)
- [`ggplot2`](http://docs.ggplot2.org/current/); visit [this site](http://www.ggplot2-exts.org/) for `ggplot2` extensions and [here](http://vita.had.co.nz/papers/layered-grammar.pdf) to read about the grammar of graphics
- [`stringr`](https://github.com/tidyverse/stringr), working with text strings, highly recommend
- [`lubridate`](https://github.com/hadley/lubridate), working with dates
- [`readr`](https://github.com/tidyverse/readr), reading tabular data
- [`readxl`](https://github.com/tidyverse/readxl), reading Microsoft Excel files
- [`haven`](https://github.com/tidyverse/haven), reading SPSS, SAS, and Stata data files, highly recommend

**Watch videos about R**

- [Analysis Pipelines](https://www.rstudio.com/resources/webinars/pipelines-for-data-analysis-in-r/), I highly recommend this talk
- [Data Wrangling](https://www.rstudio.com/resources/webinars/data-wrangling-with-r-and-rstudio/)
- [All Webinars from Rstudio](https://www.rstudio.com/resources/webinars/)

**Other resources**

- [diagrams](http://rich-iannone.github.io/DiagrammeR/index.html)
- pretty tables: [here](https://rstudio.github.io/DT/) and [here](https://cran.r-project.org/web/packages/pixiedust/vignettes/pixiedust.html)
- [list of useful packages](https://www.rstudio.com/products/rpackages/)
- [cheatsheets](https://www.rstudio.com/resources/cheatsheets/)
- [R Open Science](http://ropensci.org/)
- [`assertr`](https://github.com/ropenscilabs/assertr), for spotting errors in data, highly recommend

I will probably keep adding to this list but these are most of the resources I've gathered and find the most useful.

<script>
  var x = document.getElementsByClassName("level1");
  var i;
  for (i = 0; i < x.length; i++) {
    x[i].setAttribute("id","red" + i);
  }
</script>

<script>
  var x = document.getElementsByClassName("level2");
  var i;
  for (i = 0; i < x.length; i++) {
    x[i].setAttribute("id","green" + i);
}
</script>

<script>
  $(document).ready(function(){
    $("li.tocify-item").removeAttr("data-unique");
  });
</script>

<script>
  $(document).ready(function(){
    $("div#red0").show().siblings().hide();
      $("#header").show();
  });
</script>

<script>
  $(document).ready(function(){
    $("ul.tocify-header").click(function(){
      var myindex = $(this).index();
      $("div#red" + myindex).fadeIn(500).siblings().hide();
      $("#header").show();
      window.scrollTo(0,0);
    });
  });
</script>

<script>
  $(document).ready(function(){
    $("div#header").addClass("jumbotron").css({"position":"fixed",
                                               "width":"70%",
                                               "background-color":"white",
                                               "margin-top":"0",
                                               "margin-bottom":"0",
                                               "padding-left":"5px",
                                               "padding-top":"0",
                                               "padding-bottom":"0",
                                               "padding-right": "0",
                                               "border-bottom":"1px solid",
                                               "border-radius":"0",
                                               "border-color":"rgb(204,204,204)",
                                               "z-index":"100"});
    $("div#header button").css({"top":"10px",
                                "right":"10px"})
  });
</script>

<script>
  $(document).ready(function(){
    var myhgt = $(".jumbotron").outerHeight(true);
    $("div.level1").css("margin-top",myhgt + 10);
});
</script>

