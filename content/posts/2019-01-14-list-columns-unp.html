---
title: A Method for Estimating Environmental Statistics from Longitudinal Data
description: "Using list columns to run individual regressions and extract model statistics."
author: Ethan Young
date: '2019-01-14'
tocbot: true
slug: list-columns-unp
tags:
- R
- unpredictability
- code
---



<div id="introduction" class="section level3">
<h3>Introduction</h3>
<p>A key variable in evolutionary-developmental researh is environmental unpredictability, or the extent to which environmental parameters fluctuate randomly. However, environmental unpredictability has taken on a number of different definitions. For example, from a theoretical perspective, unpredictability is defined as random fluctuations in the rates of mortality and morbidity in a given environment. In human research, however, unpredictability has been operationalized as a subset of items from a stress interview that are thought to be indicative of an unpredictable environement such as the number of job changes mothers experienced, the number of residential moves the family experienced, and the number of different romantic partners that had moved in or out of a household during childhood. Other human assessments of unpredictability use items that measure the level of chaos in home. Despite the content-validity of some of these instruments and theory-consistent empirical findings produced by studies using them, the fact remains that these items do not directly assess variability the environment, that is, real fluctations in the state of the environment over time.</p>
<p>Developmental researchers will often use mixed-effects models or growth curve analysis to analyze change over time for a particular variable. These models allow researchers to test the effects of particular variables on the intercept and slope of a dependent variable across time. However, one might also be interested in quantifying not only intercepts and slopes but also residual variance and/or model fit statistics. As such, the following post tries to unpack a possible way to fit individual linear models to a list column for every case contained in a dataset. By extracting parameters from these models, such as R<sup>2</sup> or deviance, information beyond simple intercepts and slopes can be obtained and used in other analyses. The method utlizes here takes advantage of list columns, which are essentially lists contained within a <code>data.frame</code> and thereby faciliates the storage of lists for every observation or case in a dataset in a clean and organized way. Using the <code>nest()</code> and <code>unnest()</code> functions from the R-package <code>tidyr</code>, we can work with these lists efficiently.</p>
</div>
<div id="setup" class="section level3">
<h3>Setup</h3>
<p>Below are the packages needed to reproduce the results from this post. Be sure to use <code>set.seed()</code> to obtain the exact same results as presented here.</p>
<pre class="r"><code># packages
library(tidyverse)
library(broom)

# ggplot theme
extrafont::loadfonts()

theme_set(
  theme_light() +
    theme(
      text = element_text(family=&quot;Lato&quot;)
    )
)

# setting the seed for reproducibility
set.seed(4523)</code></pre>
</div>
<div id="contrived-examples" class="section level3">
<h3>Contrived examples</h3>
<p>To illustrate the method conceptually, let’s imagine a few way concrete ways in which the environment could change across time. Specifically, let’s assume that we can measure the environment in a reliable and valid manner across time. Below, I create a dataset containing 10 individuals each with ten measurements of their environemnt. Note that time stamps for these measurements are containted within the <code>time</code> column of this <code>data.frame</code>. Also note that this column is a list column, or a column of lists for each observation.</p>
<pre class="r"><code>example_data &lt;- expand.grid(variance = c(0,1), intercept = c(-5,0,5),slope = c(-1,0,1)) %&gt;% 
  as_tibble() %&gt;% 
  mutate(
    id   = 1:n(),
    time = list(1:10)
  )

example_data</code></pre>
<pre><code>## # A tibble: 18 x 5
##    variance intercept slope    id time      
##       &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;list&gt;    
##  1        0        -5    -1     1 &lt;int [10]&gt;
##  2        1        -5    -1     2 &lt;int [10]&gt;
##  3        0         0    -1     3 &lt;int [10]&gt;
##  4        1         0    -1     4 &lt;int [10]&gt;
##  5        0         5    -1     5 &lt;int [10]&gt;
##  6        1         5    -1     6 &lt;int [10]&gt;
##  7        0        -5     0     7 &lt;int [10]&gt;
##  8        1        -5     0     8 &lt;int [10]&gt;
##  9        0         0     0     9 &lt;int [10]&gt;
## 10        1         0     0    10 &lt;int [10]&gt;
## 11        0         5     0    11 &lt;int [10]&gt;
## 12        1         5     0    12 &lt;int [10]&gt;
## 13        0        -5     1    13 &lt;int [10]&gt;
## 14        1        -5     1    14 &lt;int [10]&gt;
## 15        0         0     1    15 &lt;int [10]&gt;
## 16        1         0     1    16 &lt;int [10]&gt;
## 17        0         5     1    17 &lt;int [10]&gt;
## 18        1         5     1    18 &lt;int [10]&gt;</code></pre>
<p>With this data structure, we can imagine at least 3 important parameters that could capture different patterns of environmental change:</p>
<ol style="list-style-type: decimal">
<li>Intercepts: mean levels of harshness</li>
<li>Slopes: the overall trajectory of change over time in the level of harshness</li>
<li>Residual Variance: fluctuations in harshness around the overall trajectory of harshness</li>
</ol>
<p>With these parameters, we can visualize different hypothetical patterns of change over time. For example, it is possible to have an overall low, average, or high level of harshness across time with either a negative, flat, or positive trajectory. In addition, each pattern could be characteried by high or low residual variance.</p>
<p>To visualize there patterns, I can unnest the dataset created above and create environmental stress measures as a function of a linear combination of differing intercepts and slopes with either high or low variance.</p>
<pre class="r"><code>example_data &lt;- example_data %&gt;% 
  unnest() %&gt;% 
  group_by(id) %&gt;% 
  mutate(
    h_var     = rnorm(10, mean = 0, sd = 5),
    l_var     = rnorm(10, mean = 0, sd = 1),
    stress    = case_when(variance == 0 ~ intercept + time*slope + l_var,
                          variance == 1 ~ intercept + time*slope + h_var),
    intercept = factor(intercept, levels = c(5,0,-5), labels = c(&quot;low&quot;,&quot;medium&quot;,&quot;high&quot;)),
    slope     = factor(slope, levels = c(1,0,-1),labels = c(&quot;positive&quot;,&quot;zero&quot;,&quot;negative&quot;))
  )</code></pre>
<p>The contrived dataset contains differing hypothetical developmental trajectories with both high and low variance</p>
<div id="low-variance" class="section level4">
<h4>Low Variance</h4>
<pre class="r"><code>example_data %&gt;% 
  filter(variance==0) %&gt;% 
  ggplot(aes(x = time, y = stress)) +
  geom_point() +
  stat_smooth(method = &quot;lm&quot;) +
  facet_grid(slope~intercept, scales=&quot;free_y&quot;) +
  scale_x_continuous(&quot;Time&quot;,breaks = 1:10) +
  scale_y_continuous(&quot;Stress Exposure Level&quot;) +
  labs(title = &quot;Low Variance Stress Exposure Trajectories&quot;,
       subtitle = &quot;Columns are intercepts, rows are slopes&quot;)</code></pre>
<p><img src="/posts/2019-01-14-list-columns-unp_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
</div>
<div id="high-variance" class="section level4">
<h4>High Variance</h4>
<pre class="r"><code>example_data %&gt;% 
  filter(variance==1) %&gt;% 
  ggplot(aes(x = time, y = stress)) +
  geom_point() +
  stat_smooth(method = &quot;lm&quot;) +
  facet_grid(slope~intercept, scales=&quot;free_y&quot;) +
  scale_x_continuous(&quot;Time&quot;,breaks = 1:10) +
  scale_y_continuous(&quot;Stress Exposure Level&quot;) +
  labs(title = &quot;Low Variance Stress Exposure Trajectories&quot;,
       subtitle = &quot;Columns are intercepts, rows are slopes&quot;)</code></pre>
<p><img src="/posts/2019-01-14-list-columns-unp_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
</div>
<div id="simulated-empirical-data" class="section level3">
<h3>Simulated Empirical Data</h3>
<p>Now that we have conceptualized different trajectories of environmental stress across time with varying combinations of intercepts, slopes, and residual variance, we can apply a method for calculating and extracting these parameters for a given longitudinal dataset.</p>
<p>To illustrate, I created random data following the same structure as the examples above. I randomly vary the mean level of stress exposure for each participants repeated measurements of the environment along with randomly varying standard deviations.</p>
<pre class="r"><code>stress_df &lt;- map_df(1:10, function(x){
  tibble(id     = x,
         time   = c(1:10),
         stress = rnorm(n = 10, mean = sample(-5:5,1), sd = sample(seq(0,10,.1),1)))
})</code></pre>
</div>
<div id="calculate-individual-regressions" class="section level3">
<h3>Calculate Individual Regressions</h3>
<p>Next, we can nest the data to compress each participant’s stress data into a list. By specifying a function that simply calculates a simple regression of stress on time, we can interate of each observation’s stress data contained within a list and save the results in a new list column containing each observation’s regression model.</p>
<pre class="r"><code># Functions
stress.lm &lt;- function(df){
  lm(stress~time,data=df)
}

# Nest Data
stress_df_nested &lt;- stress_df %&gt;% 
  group_by(id) %&gt;% 
  nest()

# Fit a linear model to each observation
stress_models &lt;- stress_df_nested %&gt;% 
  group_by(id) %&gt;% 
  mutate(
    stress_lm    = map(data,stress.lm),
    lm_stats     = map(stress_lm,glance),
    lm_coefs     = map(stress_lm,tidy),
    lm_vals      = map(stress_lm,augment),
    lm_intercept = map_dbl(lm_coefs, function(x) unlist(x[1,&quot;estimate&quot;])),
    lm_slope     = map_dbl(lm_coefs, function(x) unlist(x[2,&quot;estimate&quot;])),
    lm_rsqrd     = lm_stats %&gt;% map_dbl(&quot;r.squared&quot;),
    lm_deviance  = lm_stats %&gt;% map_dbl(&quot;deviance&quot;),
    lm_sigma     = lm_stats %&gt;% map_dbl(&quot;sigma&quot;)
  )</code></pre>
<p>From each regression, we can extract interesting data, such as the predicted values and residuals values, and overall model parameters, such as the intercept, slope, R<sup>2</sup>, and deviance.</p>
<p>To unpack these data, we can plot each of the participants data:</p>
<pre class="r"><code># Plot all participants
stress_models %&gt;% 
  select(lm_vals) %&gt;%  
  unnest() %&gt;% 
  ggplot(aes(x = time, y = stress)) +
  geom_segment(aes(x = time, xend = time, y = stress, yend= stress - .resid), color = &quot;red&quot;) +
  stat_smooth(aes(x=time,y = stress), method = &quot;loess&quot;, se = F,span = 1) +
  geom_point() +
  geom_line(aes(y = .fitted),size=1) +
  geom_point(aes(y = .fitted),shape=21,fill=&quot;white&quot;) +
  scale_x_continuous(&quot;Time&quot;, breaks = 1:10) +
  facet_wrap(~id,nrow = 5)</code></pre>
<p><img src="/posts/2019-01-14-list-columns-unp_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>These plots visualize each observation’s trajectory, including their intercept, slope, and residual variance. In addition, we can see a few of the model parameters that we extracted from each individual’s model:</p>
<pre class="r"><code># Regression model parameters extracted from each participant
stress_models %&gt;% 
  select(id,lm_intercept,lm_slope,lm_rsqrd,lm_deviance,lm_sigma) %&gt;% 
  knitr::kable(digits = 2, format = &quot;html&quot;, table.attr = &quot;class=\&quot;bordered\&quot;&quot;)</code></pre>
<table class="bordered">
<thead>
<tr>
<th style="text-align:right;">
id
</th>
<th style="text-align:right;">
lm_intercept
</th>
<th style="text-align:right;">
lm_slope
</th>
<th style="text-align:right;">
lm_rsqrd
</th>
<th style="text-align:right;">
lm_deviance
</th>
<th style="text-align:right;">
lm_sigma
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
3.74
</td>
<td style="text-align:right;">
0.38
</td>
<td style="text-align:right;">
0.10
</td>
<td style="text-align:right;">
109.36
</td>
<td style="text-align:right;">
3.70
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
5.15
</td>
<td style="text-align:right;">
-1.39
</td>
<td style="text-align:right;">
0.38
</td>
<td style="text-align:right;">
257.04
</td>
<td style="text-align:right;">
5.67
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
1.62
</td>
<td style="text-align:right;">
-1.24
</td>
<td style="text-align:right;">
0.40
</td>
<td style="text-align:right;">
187.70
</td>
<td style="text-align:right;">
4.84
</td>
</tr>
<tr>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
-4.62
</td>
<td style="text-align:right;">
-0.14
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
386.62
</td>
<td style="text-align:right;">
6.95
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
7.53
</td>
<td style="text-align:right;">
-0.96
</td>
<td style="text-align:right;">
0.30
</td>
<td style="text-align:right;">
172.83
</td>
<td style="text-align:right;">
4.65
</td>
</tr>
<tr>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
-3.11
</td>
<td style="text-align:right;">
0.20
</td>
<td style="text-align:right;">
0.48
</td>
<td style="text-align:right;">
3.75
</td>
<td style="text-align:right;">
0.68
</td>
</tr>
<tr>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
-5.14
</td>
<td style="text-align:right;">
-0.28
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
121.74
</td>
<td style="text-align:right;">
3.90
</td>
</tr>
<tr>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
4.64
</td>
<td style="text-align:right;">
0.04
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
1.88
</td>
<td style="text-align:right;">
0.48
</td>
</tr>
<tr>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
-8.21
</td>
<td style="text-align:right;">
0.56
</td>
<td style="text-align:right;">
0.06
</td>
<td style="text-align:right;">
398.70
</td>
<td style="text-align:right;">
7.06
</td>
</tr>
<tr>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
-2.92
</td>
<td style="text-align:right;">
-0.25
</td>
<td style="text-align:right;">
0.37
</td>
<td style="text-align:right;">
8.46
</td>
<td style="text-align:right;">
1.03
</td>
</tr>
</tbody>
</table>
<p>The main idea here is that we can use this method to extract interesting parameters not normally leveraged in mixed-models and use them in further analysis, such as looking at how residual variance, a potential measure of unpredictability, might be a unique predictor of different kinds of outcomes.</p>
</div>
